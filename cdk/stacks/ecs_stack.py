from aws_cdk import (
    Stack,
    Duration,
    aws_ecs as ecs,
    aws_ecs_patterns as ecs_patterns,
    aws_iam as iam,
    aws_logs as logs,
    aws_ec2 as ec2,
    CfnOutput
)
from constructs import Construct

class EcsStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, vpc, secrets, knowledge_base_id, data_bucket, opensearch_endpoint, vector_lambda_arn, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        # ECS Cluster
        cluster = ecs.Cluster(
            self, "NotionChatbotCluster",
            vpc=vpc,
            cluster_name="notion-chatbot-cluster",
            enable_fargate_capacity_providers=True
        )

        # Task Role - Bedrock ë° Secrets Manager ì ‘ê·¼ ê¶Œí•œ
        task_role = iam.Role(
            self, "NotionChatbotTaskRole",
            assumed_by=iam.ServicePrincipal("ecs-tasks.amazonaws.com"),
            managed_policies=[
                iam.ManagedPolicy.from_aws_managed_policy_name("service-role/AmazonECSTaskExecutionRolePolicy")
            ]
        )

        # S3 ì ‘ê·¼ ê¶Œí•œ ì¶”ê°€
        data_bucket.grant_read(task_role)
        task_role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "s3:ListBucket"
                ],
                resources=[data_bucket.bucket_arn]
            )
        )

        # OpenSearch ì ‘ê·¼ ê¶Œí•œ ì¶”ê°€
        task_role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "aoss:APIAccessAll"
                ],
                resources=["*"]
            )
        )

        # Bedrock Titan Embedding ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ ì¶”ê°€
        task_role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "bedrock:InvokeModel"
                ],
                resources=[
                    f"arn:aws:bedrock:{self.region}::foundation-model/amazon.titan-embed-text-v1"
                ]
            )
        )
        # Lambda í˜¸ì¶œ ê¶Œí•œ ì¶”ê°€ (ê¸°ì¡´ + ë²¡í„° Lambda)
        task_role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "lambda:InvokeFunction"
                ],
                resources=[
                    f"arn:aws:lambda:{self.region}:{self.account}:function:NotionChatbotBedrockStack-NotionSyncFunction*",
                    vector_lambda_arn
                ]
            )
        )

        # Bedrock ì ‘ê·¼ ê¶Œí•œ ì¶”ê°€
        task_role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "bedrock:InvokeModel",
                    "bedrock:InvokeModelWithResponseStream",
                    "bedrock:Retrieve",
                    "bedrock:RetrieveAndGenerate"
                ],
                resources=[
                    f"arn:aws:bedrock:{self.region}::foundation-model/anthropic.claude-3-haiku-20240307-v1:0",
                    f"arn:aws:bedrock:{self.region}:{self.account}:knowledge-base/{knowledge_base_id}"
                ]
            )
        )

        # Secrets Manager ì ‘ê·¼ ê¶Œí•œ ì¶”ê°€
        for secret in secrets.values():
            secret.grant_read(task_role)

        # Task Definition
        task_definition = ecs.FargateTaskDefinition(
            self, "NotionChatbotTaskDef",
            memory_limit_mib=1024,
            cpu=512,
            task_role=task_role
        )

        # Container Definition
        container = task_definition.add_container(
            "NotionChatbotContainer",
            image=ecs.ContainerImage.from_registry("python:3.11-slim"),
            logging=ecs.LogDrivers.aws_logs(
                stream_prefix="notion-chatbot",
                log_group=logs.LogGroup(
                    self, "NotionChatbotLogGroup",
                    log_group_name="/ecs/notion-chatbot",
                    retention=logs.RetentionDays.ONE_WEEK
                )
            ),
            environment={
                "AWS_DEFAULT_REGION": self.region,
                "STREAMLIT_SERVER_PORT": "8501",
                "STREAMLIT_SERVER_ADDRESS": "0.0.0.0",
                "NOTION_TOKEN": "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",
                "KNOWLEDGE_BASE_ID": knowledge_base_id,
                "OPENSEARCH_ENDPOINT": opensearch_endpoint,
                "VECTOR_LAMBDA_ARN": vector_lambda_arn
            },
            secrets={
                "NOTION_TOKEN_SECRET_ARN": ecs.Secret.from_secrets_manager(secrets["notion_token"]),
                "APP_CONFIG_SECRET_ARN": ecs.Secret.from_secrets_manager(secrets["app_config"])
            },
            command=[
                "sh", "-c", 
                "pip install streamlit boto3 requests notion-client opensearch-py && "
                "mkdir -p /app && cd /app && "
                "cat > opensearch_client.py << 'OPENSEARCH_EOF'\n"
                "import json\n"
                "import boto3\n"
                "import requests\n"
                "from typing import List, Dict, Any\n"
                "import streamlit as st\n"
                "\n"
                "class OpenSearchClient:\n"
                "    def __init__(self, endpoint: str):\n"
                "        self.endpoint = endpoint\n"
                "        self.bedrock_client = boto3.client('bedrock-runtime', region_name='ap-northeast-2')\n"
                "    \n"
                "    def generate_embedding(self, text: str) -> List[float]:\n"
                "        try:\n"
                "            response = self.bedrock_client.invoke_model(\n"
                "                modelId='amazon.titan-embed-text-v1',\n"
                "                body=json.dumps({'inputText': text[:8000]})\n"
                "            )\n"
                "            response_body = json.loads(response['body'].read())\n"
                "            return response_body['embedding']\n"
                "        except Exception as e:\n"
                "            st.error(f'ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}')\n"
                "            return []\n"
                "    \n"
                "    def semantic_search(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:\n"
                "        try:\n"
                "            query_embedding = self.generate_embedding(query)\n"
                "            if not query_embedding:\n"
                "                return []\n"
                "            \n"
                "            search_body = {\n"
                "                'size': limit,\n"
                "                'query': {\n"
                "                    'knn': {\n"
                "                        'embedding': {\n"
                "                            'vector': query_embedding,\n"
                "                            'k': limit\n"
                "                        }\n"
                "                    }\n"
                "                },\n"
                "                '_source': ['id', 'title', 'content', 'url', 'metadata']\n"
                "            }\n"
                "            \n"
                "            response = requests.post(\n"
                "                f'{self.endpoint}/notion-index/_search',\n"
                "                json=search_body,\n"
                "                headers={'Content-Type': 'application/json'}\n"
                "            )\n"
                "            \n"
                "            if response.status_code == 200:\n"
                "                results = response.json()\n"
                "                documents = []\n"
                "                for hit in results.get('hits', {}).get('hits', []):\n"
                "                    source = hit['_source']\n"
                "                    documents.append({\n"
                "                        'id': source.get('id'),\n"
                "                        'title': source.get('title', 'ì œëª© ì—†ìŒ'),\n"
                "                        'content': source.get('content', ''),\n"
                "                        'url': source.get('url', ''),\n"
                "                        'similarity_score': hit['_score']\n"
                "                    })\n"
                "                return documents\n"
                "            return []\n"
                "        except Exception as e:\n"
                "            st.error(f'ì˜ë¯¸ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')\n"
                "            return []\n"
                "OPENSEARCH_EOF\n"
                "cat > app.py << 'EOF'\n"
                "import streamlit as st\n"
                "import boto3\n"
                "import json\n"
                "import os\n"
                "from datetime import datetime\n"
                "from opensearch_client import OpenSearchClient\n"
                "\n"
                "st.set_page_config(page_title='ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ¤–', page_icon='ğŸ¤–', layout='wide')\n"
                "\n"
                "st.markdown('<div style=\"text-align: center; padding: 1rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 2rem;\"><h1>ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!</h1><p>Notion ì§€ì‹ ê¸°ë°˜ì—ì„œ ë‹µë³€ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤ (ê²€ìƒ‰ ë°©ì‹ ë¹„êµ ë°ëª¨)</p></div>', unsafe_allow_html=True)\n"
                "\n"
                "# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n"
                "@st.cache_resource\n"
                "def get_aws_clients():\n"
                "    s3 = boto3.client('s3', region_name='ap-northeast-2')\n"
                "    bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')\n"
                "    lambda_client = boto3.client('lambda', region_name='ap-northeast-2')\n"
                "    return s3, bedrock, lambda_client\n"
                "\n"
                "s3_client, bedrock_client, lambda_client = get_aws_clients()\n"
                "knowledge_base_id = os.getenv('KNOWLEDGE_BASE_ID', 'simple-kb-demo')\n"
                "opensearch_endpoint = os.getenv('OPENSEARCH_ENDPOINT', '')\n"
                "vector_lambda_arn = os.getenv('VECTOR_LAMBDA_ARN', '')\n"
                "\n"
                "# OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n"
                "opensearch_client = None\n"
                "if opensearch_endpoint:\n"
                "    opensearch_client = OpenSearchClient(opensearch_endpoint)\n"
                "\n"
                "                "def search_opensearch_documents(query, search_method='semantic'):\n"
                "    '''OpenSearchë¥¼ ì‚¬ìš©í•œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰'''\n"
                "    try:\n"
                "        if not opensearch_client:\n"
                "            st.error('OpenSearchê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')\n"
                "            return []\n"
                "        \n"
                "        if search_method == 'semantic':\n"
                "            documents = opensearch_client.semantic_search(query, limit=5)\n"
                "        else:\n"
                "            documents = opensearch_client.hybrid_search(query, limit=5)\n"
                "        \n"
                "        return documents\n"
                "        \n"
                "    except Exception as e:\n"
                "        st.error(f'OpenSearch ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')\n"
                "        return []\n"
                "\n"\n"
                "    '''S3ì—ì„œ Notion ë¬¸ì„œ ê²€ìƒ‰'''\n"
                "    try:\n"
                "        # S3ì—ì„œ notion-data/ í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ ë‚˜ì—´\n"
                "        response = s3_client.list_objects_v2(\n"
                "            Bucket=bucket_name,\n"
                "            Prefix='notion-data/',\n"
                "            MaxKeys=50\n"
                "        )\n"
                "        \n"
                "        documents = []\n"
                "        \n"
                "        if 'Contents' in response:\n"
                "            for obj in response['Contents']:\n"
                "                if obj['Key'].endswith('.json'):\n"
                "                    # ê° ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n"
                "                    doc_response = s3_client.get_object(\n"
                "                        Bucket=bucket_name,\n"
                "                        Key=obj['Key']\n"
                "                    )\n"
                "                    doc_content = json.loads(doc_response['Body'].read())\n"
                "                    \n"
                "                    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê´€ë ¨ì„± í™•ì¸\n"
                "                    query_lower = query.lower()\n"
                "                    title_lower = doc_content.get('title', '').lower()\n"
                "                    content_lower = doc_content.get('content', '').lower()\n"
                "                    \n"
                "                    # í‚¤ì›Œë“œê°€ ì œëª©ì´ë‚˜ ë‚´ìš©ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê´€ë ¨ ë¬¸ì„œë¡œ íŒë‹¨\n"
                "                    if any(word in title_lower or word in content_lower for word in query_lower.split()):\n"
                "                        documents.append(doc_content)\n"
                "        \n"
                "        return documents[:5]  # ìµœëŒ€ 5ê°œ ë¬¸ì„œ ë°˜í™˜\n"
                "        \n"
                "    except Exception as e:\n"
                "        st.error(f'S3 ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')\n"
                "        return []\n"
                "\n"
                "def generate_bedrock_response(query, documents):\n"
                "    '''Bedrockìœ¼ë¡œ RAG ì‘ë‹µ ìƒì„±'''\n"
                "    try:\n"
                "        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n"
                "        context_parts = []\n"
                "        for doc in documents:\n"
                "            title = doc.get('title', 'ì œëª© ì—†ìŒ')\n"
                "            content = doc.get('content', '')[:500]  # ì²˜ìŒ 500ìë§Œ ì‚¬ìš©\n"
                "            context_parts.append(f'ë¬¸ì„œ: {title}\\në‚´ìš©: {content}')\n"
                "        \n"
                "        context = '\\n\\n'.join(context_parts)\n"
                "        \n"
                "        # Claude 3 Haiku í”„ë¡¬í”„íŠ¸\n"
                "        prompt = f'''ì‚¬ìš©ì ì§ˆë¬¸: {query}\n"
                "\n"
                "ê´€ë ¨ Notion ë¬¸ì„œë“¤:\n"
                "{context}\n"
                "\n"
                "ìœ„ì˜ Notion ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”. ë‹µë³€í•  ë•ŒëŠ” ë‹¤ìŒ ì‚¬í•­ì„ ì§€ì¼œì£¼ì„¸ìš”:\n"
                "1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”\n"
                "2. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n"
                "3. ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”\n"
                "4. ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”'''\n"
                "        \n"
                "        # Bedrock í˜¸ì¶œ\n"
                "        body = {\n"
                "            'anthropic_version': 'bedrock-2023-05-31',\n"
                "            'max_tokens': 2000,\n"
                "            'temperature': 0.1,\n"
                "            'messages': [{'role': 'user', 'content': prompt}]\n"
                "        }\n"
                "        \n"
                "        response = bedrock_client.invoke_model(\n"
                "            modelId='anthropic.claude-3-haiku-20240307-v1:0',\n"
                "            body=json.dumps(body)\n"
                "        )\n"
                "        \n"
                "        response_body = json.loads(response['body'].read())\n"
                "        return response_body['content'][0]['text']\n"
                "        \n"
                "    except Exception as e:\n"
                "        return f'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'\n"
                "\n"
                "# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”\n"
                "if 'messages' not in st.session_state:\n"
                "    st.session_state.messages = []\n"
                "\n"
                "# ì´ì „ ë©”ì‹œì§€ë“¤ í‘œì‹œ\n"
                "for message in st.session_state.messages:\n"
                "    with st.chat_message(message['role']):\n"
                "        st.markdown(message['content'])\n"
                "        if message.get('sources'):\n"
                "            with st.expander('ğŸ“š ì°¸ê³  ë¬¸ì„œ'):\n"
                "                for i, source in enumerate(message['sources'], 1):\n"
                "                    st.markdown(f'**{i}. {source.get(\"title\", \"ë¬¸ì„œ\")}**')\n"
                "                    content_preview = source.get(\"content\", \"ë‚´ìš© ì—†ìŒ\")[:200]\n"
                "                    st.markdown(f'ë‚´ìš©: {content_preview}...')\n"
                "                    if source.get('url'):\n"
                "                        st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({source[\"url\"]})')\n"
                "                    st.markdown('---')\n"
                "\n"
                "# ì‚¬ìš©ì ì…ë ¥\n"
                "if prompt := st.chat_input('ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ì˜ˆ: í”„ë¡œì íŠ¸ ì¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'):\n"
                "    st.session_state.messages.append({'role': 'user', 'content': prompt})\n"
                "    \n"
                "    with st.chat_message('user'):\n"
                "        st.markdown(prompt)\n"
                "    \n"
                "    with st.chat_message('assistant'):\n"
                "        with st.spinner('S3ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ¤”'):\n"
                "            try:\n"
                "                # S3 ë²„í‚· ì´ë¦„\n"
                "                bucket_name = f'notion-chatbot-data-965037532757-ap-northeast-2'\n"
                "                \n"
                "                # ì„ íƒëœ ê²€ìƒ‰ ë°©ì‹ì— ë”°ë¼ ë¬¸ì„œ ê²€ìƒ‰\n"
                "                if search_method == 'S3 í‚¤ì›Œë“œ ê²€ìƒ‰':\n"
                "                    documents = search_s3_documents(prompt, bucket_name)\n"
                "                    search_info = f'ğŸ” S3 í‚¤ì›Œë“œ ê²€ìƒ‰ ì‚¬ìš©'\n"
                "                else:\n"
                "                    documents = search_opensearch_documents(prompt)\n"
                "                    search_info = f'ğŸ§  OpenSearch ì˜ë¯¸ ê²€ìƒ‰ ì‚¬ìš©'\n"
                "                \n"
                "                st.info(search_info)\n"
                "                \n"
                "                if documents:\n"
                "                    # Bedrockìœ¼ë¡œ RAG ì‘ë‹µ ìƒì„±\n"
                "                    answer = generate_bedrock_response(prompt, documents)\n"
                "                    st.markdown(answer)\n"
                "                    \n"
                "                    # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ\n"
                "                    with st.expander('ğŸ“š ì°¸ê³  ë¬¸ì„œ', expanded=True):\n"
                "                        for i, doc in enumerate(documents[:3], 1):\n"
                "                            st.markdown(f'**{i}. {doc.get(\"title\", \"ë¬¸ì„œ\")}**')\n"
                "                            content_preview = doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]\n"
                "                            st.markdown(f'ë‚´ìš©: {content_preview}...')\n"
                "                            if doc.get('url'):\n"
                "                                st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({doc[\"url\"]})')\n"
                "                            st.markdown('---')\n"
                "                    \n"
                "                    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€\n"
                "                    st.session_state.messages.append({\n"
                "                        'role': 'assistant', \n"
                "                        'content': answer,\n"
                "                        'sources': documents\n"
                "                    })\n"
                "                else:\n"
                "                    no_result_msg = 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Notion ë°ì´í„°ê°€ ë™ê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.'\n"
                "                    st.markdown(no_result_msg)\n"
                "                    st.session_state.messages.append({'role': 'assistant', 'content': no_result_msg})\n"
                "                    \n"
                "            except Exception as e:\n"
                "                error_msg = f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'\n"
                "                st.error(error_msg)\n"
                "                st.session_state.messages.append({'role': 'assistant', 'content': error_msg})\n"
                "\n"
                "# ì‚¬ì´ë“œë°”\n"
                "with st.sidebar:\n"
                "    st.markdown('## âš™ï¸ ì„¤ì •')\n"
                "    \n"
                "    # ê²€ìƒ‰ ë°©ì‹ ì„ íƒ\n"
                "    st.markdown('### ğŸ” ê²€ìƒ‰ ë°©ì‹ ì„ íƒ')\n"
                "    search_method = st.selectbox(\n"
                "        'ê²€ìƒ‰ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:',\n"
                "        ['S3 í‚¤ì›Œë“œ ê²€ìƒ‰', 'OpenSearch ì˜ë¯¸ ê²€ìƒ‰'],\n"
                "        help='S3: í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜, OpenSearch: ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰'\n"
                "    )\n"
                "    \n"
                "    # ê²€ìƒ‰ ë°©ì‹ë³„ ì„¤ëª…\n"
                "    if search_method == 'S3 í‚¤ì›Œë“œ ê²€ìƒ‰':\n"
                "        st.info('ğŸ“ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ê²€ìƒ‰\\n- ë¹ ë¥¸ ì†ë„\\n- ì •í™•í•œ í‚¤ì›Œë“œ ì¼ì¹˜\\n- ë¹„ìš© íš¨ìœ¨ì ')\n"
                "    else:\n"
                "        st.info('ğŸ§  ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰\\n- ë¬¸ë§¥ ì´í•´\\n- ìœ ì‚¬í•œ ì˜ë¯¸ ê²€ìƒ‰\\n- ë†’ì€ ì •í™•ë„')\n"
                "    \n"
                "    # Knowledge Base ì •ë³´\n"
                "    st.markdown('### ğŸ§  Knowledge Base')\n"
                "    st.success(f'S3 ê¸°ë°˜ ê²€ìƒ‰: {knowledge_base_id}')\n"
                "    \n"
                "    if st.button('ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”'):\n"
                "        st.session_state.messages = []\n"
                "        st.rerun()\n"
                "    \n"
                "    if st.button('ğŸ”„ ë°ì´í„° ë™ê¸°í™” ì‹¤í–‰'):\n"
                "        sync_type = st.radio('ë™ê¸°í™” ë°©ì‹:', ['S3ë§Œ ë™ê¸°í™”', 'S3 + OpenSearch ë™ê¸°í™”'])\n"
                "        \n"
                "        if st.button('ë™ê¸°í™” ì‹œì‘'):\n"
                "            try:\n"
                "                # S3 ë™ê¸°í™”\n"
                "                response = lambda_client.invoke(\n"
                "                    FunctionName='NotionChatbotBedrockStack-NotionSyncFunctionFFED61-DntTQBnmfaiG',\n"
                "                    InvocationType='Event'\n"
                "                )\n"
                "                st.success('S3 ë™ê¸°í™” ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤!')\n"
                "                \n"
                "                # OpenSearch ë™ê¸°í™” (ì„ íƒëœ ê²½ìš°)\n"
                "                if sync_type == 'S3 + OpenSearch ë™ê¸°í™”' and vector_lambda_arn:\n"
                "                    vector_response = lambda_client.invoke(\n"
                "                        FunctionName=vector_lambda_arn.split(':')[-1],\n"
                "                        InvocationType='Event'\n"
                "                    )\n"
                "                    st.success('OpenSearch ë²¡í„° ì¸ë±ì‹± ì‘ì—…ë„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤!')\n"
                "                    \n"
                "            except Exception as e:\n"
                "                st.error(f'ë™ê¸°í™” ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}')\n"
                "    \n"
                "    st.markdown('### ğŸ’¡ S3 + RAG ë°©ì‹ íŠ¹ì§•')\n"
                "    st.markdown('- Notion ë°ì´í„°ê°€ S3ì— JSONìœ¼ë¡œ ì €ì¥ë¨\\n- í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰\\n- Claude 3 Haikuë¡œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€\\n- ì‹¤ì‹œê°„ ì†ŒìŠ¤ ì¶”ì  ê°€ëŠ¥')\n"
                "    \n"
                "    st.markdown('### ğŸ“Š í†µê³„')\n"
                "    if st.session_state.messages:\n"
                "        total = len(st.session_state.messages)\n"
                "        user_msgs = len([m for m in st.session_state.messages if m['role'] == 'user'])\n"
                "        ai_msgs = len([m for m in st.session_state.messages if m['role'] == 'assistant'])\n"
                "        sources_count = sum(len(m.get('sources', [])) for m in st.session_state.messages if m['role'] == 'assistant')\n"
                "        \n"
                "        st.metric('ì´ ë©”ì‹œì§€', total)\n"
                "        st.metric('ì‚¬ìš©ì ì§ˆë¬¸', user_msgs)\n"
                "        st.metric('AI ì‘ë‹µ', ai_msgs)\n"
                "        st.metric('ì°¸ì¡° ë¬¸ì„œ', sources_count)\n"
                "    \n"
                "    st.markdown('### ğŸ”„ ë™ê¸°í™” ì •ë³´')\n"
                "    st.info('Notion ë°ì´í„°ëŠ” 1ì‹œê°„ë§ˆë‹¤ ìë™ ë™ê¸°í™”ë©ë‹ˆë‹¤.')\n"
                "    st.info('ìˆ˜ë™ ë™ê¸°í™” ë²„íŠ¼ìœ¼ë¡œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.')\n"
                "\n"
                "st.markdown('---')\n"
                "st.markdown('<div style=\"text-align: center; color: #666; padding: 1rem;\"><p>ğŸ” S3 í‚¤ì›Œë“œ ê²€ìƒ‰ vs ğŸ§  OpenSearch ì˜ë¯¸ ê²€ìƒ‰ ë¹„êµ ë°ëª¨</p><p>ğŸ“š ë‘ ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì˜ ì°¨ì´ë¥¼ ì§ì ‘ ì²´í—˜í•´ë³´ì„¸ìš”</p><p>ğŸ”„ 1ì‹œê°„ë§ˆë‹¤ Notion ë°ì´í„° ìë™ ë™ê¸°í™”</p></div>', unsafe_allow_html=True)\n"
                "EOF\n"
                "streamlit run app.py --server.port=8501 --server.address=0.0.0.0"
            ]
        )

        # Port Mapping
        container.add_port_mappings(
            ecs.PortMapping(
                container_port=8501,
                protocol=ecs.Protocol.TCP
            )
        )

        # Application Load Balanced Fargate Service
        self.fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(
            self, "NotionChatbotService",
            cluster=cluster,
            task_definition=task_definition,
            public_load_balancer=True,
            listener_port=80,
            desired_count=1,  # ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ 1ê°œ ì¸ìŠ¤í„´ìŠ¤
            platform_version=ecs.FargatePlatformVersion.LATEST,
            assign_public_ip=True,
            service_name="notion-chatbot-service"
        )

        # Health Check ì„¤ì •
        self.fargate_service.target_group.configure_health_check(
            path="/",
            healthy_http_codes="200",
            timeout=Duration.seconds(10),
            interval=Duration.seconds(30),
            healthy_threshold_count=2,
            unhealthy_threshold_count=5
        )

        # Auto Scaling ì„¤ì • (ì„ íƒì‚¬í•­)
        scaling = self.fargate_service.service.auto_scale_task_count(
            min_capacity=1,
            max_capacity=3
        )

        scaling.scale_on_cpu_utilization(
            "CpuScaling",
            target_utilization_percent=70,
            scale_in_cooldown=Duration.minutes(5),
            scale_out_cooldown=Duration.minutes(2)
        )

        # Outputs
        CfnOutput(
            self, "LoadBalancerDNS",
            value=self.fargate_service.load_balancer.load_balancer_dns_name,
            description="Load Balancer DNS Name"
        )

        CfnOutput(
            self, "ServiceURL",
            value=f"http://{self.fargate_service.load_balancer.load_balancer_dns_name}",
            description="Notion Chatbot Service URL"
        )
