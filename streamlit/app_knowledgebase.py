import streamlit as st
import boto3
import json
import os
import requests
from datetime import datetime
from typing import List, Dict, Any

st.set_page_config(page_title='ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ¤–', page_icon='ğŸ¤–', layout='wide')

st.markdown('<div style="text-align: center; padding: 1rem 0; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 2rem;"><h1>ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!</h1><p>Notion ì§€ì‹ ê¸°ë°˜ì—ì„œ ë‹µë³€ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤ (KnowledgeBase vs S3 ê²€ìƒ‰ ë¹„êµ)</p></div>', unsafe_allow_html=True)

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_aws_clients():
    s3 = boto3.client('s3', region_name='ap-northeast-2')
    bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')
    bedrock_agent = boto3.client('bedrock-agent-runtime', region_name='ap-northeast-2')
    lambda_client = boto3.client('lambda', region_name='ap-northeast-2')
    return s3, bedrock, bedrock_agent, lambda_client

s3_client, bedrock_client, bedrock_agent_client, lambda_client = get_aws_clients()
knowledge_base_id = os.getenv('KNOWLEDGE_BASE_ID', 'UXF2GSP5IT')
opensearch_endpoint = os.getenv('OPENSEARCH_ENDPOINT', '')
vector_lambda_arn = os.getenv('VECTOR_LAMBDA_ARN', '')

def get_document_info_from_s3(s3_key, bucket_name):
    """S3ì—ì„œ ë¬¸ì„œ ì •ë³´ (ì œëª©, URL, ë‚´ìš©) ì¶”ì¶œ"""
    try:
        response = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
        content = response['Body'].read().decode('utf-8')
        
        # JSON íŒŒì‹±í•˜ì—¬ ì œëª©, URL, ë‚´ìš© ì¶”ì¶œ
        import json
        doc_data = json.loads(content)
        
        title = doc_data.get('title', 'ì œëª© ì—†ìŒ')
        url = doc_data.get('url', '')
        content_text = doc_data.get('content', '')
        
        return title, url, content_text
    except Exception as e:
        # íŒŒì¼ëª…ì—ì„œ ì œëª© ì¶”ì¶œ ì‹œë„
        filename = s3_key.split('/')[-1] if '/' in s3_key else s3_key
        title = filename.replace('.json', '').replace('_', ' ')
        return title, '', ''
    """Bedrock KnowledgeBaseë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰"""
    try:
        response = bedrock_agent_client.retrieve(
            knowledgeBaseId=knowledge_base_id,
            retrievalQuery={
                'text': query
            },
            retrievalConfiguration={
                'vectorSearchConfiguration': {
                    'numberOfResults': 5
                }
            }
        )
        
        documents = []
        for result in response.get('retrievalResults', []):
            documents.append({
                'content': result.get('content', {}).get('text', ''),
                'metadata': result.get('metadata', {}),
                'score': result.get('score', 0),
                'location': result.get('location', {})
            })
        
        return documents
        
    except Exception as e:
        st.error(f'KnowledgeBase ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')
        return []

def generate_knowledgebase_response_with_context(query, knowledge_base_id, conversation_history):
    """KnowledgeBaseë¥¼ ì‚¬ìš©í•œ RAG ì‘ë‹µ ìƒì„± + ì°¸ê³  ë¬¸ì„œ ì •ë³´ + ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""
    try:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_query = query
        if conversation_history:
            # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš© (í† í° ì œí•œ ê³ ë ¤)
            recent_history = conversation_history[-6:]  # ì‚¬ìš©ì-ì–´ì‹œìŠ¤í„´íŠ¸ ìŒ 3ê°œ
            context_parts = []
            
            for i in range(0, len(recent_history), 2):
                if i + 1 < len(recent_history):
                    user_msg = recent_history[i]['content']
                    assistant_msg = recent_history[i + 1]['content']
                    context_parts.append(f"ì´ì „ ì§ˆë¬¸: {user_msg}\nì´ì „ ë‹µë³€: {assistant_msg}")
            
            if context_parts:
                context_query = f"ì´ì „ ëŒ€í™” ë‚´ìš©:\n{chr(10).join(context_parts)}\n\ní˜„ì¬ ì§ˆë¬¸: {query}"
        
        # 1. retrieve_and_generateë¡œ ë‹µë³€ ìƒì„± (ì‹¤ì œ KnowledgeBase ì‚¬ìš©)
        rag_response = bedrock_agent_client.retrieve_and_generate(
            input={
                'text': context_query
            },
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': knowledge_base_id,
                    'modelArn': f'arn:aws:bedrock:ap-northeast-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'
                }
            }
        )
        
        answer = rag_response.get('output', {}).get('text', '')
        citations = rag_response.get('citations', [])
        
        # 2. citationsê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ ë³„ë„ë¡œ retrieve API í˜¸ì¶œí•˜ì—¬ ì°¸ê³  ë¬¸ì„œ ì •ë³´ ë³´ê°•
        if not citations or len(citations) == 0:
            retrieve_response = bedrock_agent_client.retrieve(
                knowledgeBaseId=knowledge_base_id,
                retrievalQuery={
                    'text': query  # ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ (ì»¨í…ìŠ¤íŠ¸ ì œì™¸)
                },
                retrievalConfiguration={
                    'vectorSearchConfiguration': {
                        'numberOfResults': 5
                    }
                }
            )
            
            # retrieve ê²°ê³¼ë¥¼ citations í˜•íƒœë¡œ ë³€í™˜
            citations = []
            for result in retrieve_response.get('retrievalResults', []):
                citation = {
                    'retrievedReferences': [{
                        'content': result.get('content', {}),
                        'location': result.get('location', {}),
                        'metadata': result.get('metadata', {}),
                        'score': result.get('score', 0)
                    }]
                }
                citations.append(citation)
        
        return answer, citations
        
    except Exception as e:
        return f'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', []

def generate_s3_response_with_context(query, bucket_name, conversation_history):
    """S3 ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± + ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""
    try:
        # S3ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
        documents = search_s3_documents(query, bucket_name)
        
        if not documents:
            return 'ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', []
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        conversation_context = ""
        if conversation_history:
            recent_history = conversation_history[-4:]  # ìµœê·¼ 2ê°œ ëŒ€í™” ìŒ
            context_parts = []
            
            for i in range(0, len(recent_history), 2):
                if i + 1 < len(recent_history):
                    user_msg = recent_history[i]['content']
                    assistant_msg = recent_history[i + 1]['content']
                    context_parts.append(f"ì‚¬ìš©ì: {user_msg}\nì–´ì‹œìŠ¤í„´íŠ¸: {assistant_msg}")
            
            if context_parts:
                conversation_context = f"\n\nì´ì „ ëŒ€í™”:\n{chr(10).join(context_parts)}\n"
        
        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        doc_context = "\n\n".join([f"ë¬¸ì„œ {i+1}: {doc['content']}" for i, doc in enumerate(documents[:3])])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ê³¼ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{doc_context}{conversation_context}

í˜„ì¬ ì§ˆë¬¸: {query}

ë‹µë³€:"""
        
        # Bedrockìœ¼ë¡œ ë‹µë³€ ìƒì„±
        response = bedrock_client.invoke_model(
            modelId='anthropic.claude-3-haiku-20240307-v1:0',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 1000,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            })
        )
        
        result = json.loads(response['body'].read())
        answer = result['content'][0]['text']
        
        return answer, documents
        
    except Exception as e:
        return f'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', []

def search_s3_documents(query, bucket_name):
    """S3ì—ì„œ ì§ì ‘ ë¬¸ì„œ ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹)"""
    try:
        response = s3_client.list_objects_v2(
            Bucket=bucket_name,
            Prefix='notion-data/',
            MaxKeys=50
        )
        
        documents = []
        
        if 'Contents' in response:
            for obj in response['Contents']:
                if obj['Key'].endswith('.json'):
                    doc_response = s3_client.get_object(
                        Bucket=bucket_name,
                        Key=obj['Key']
                    )
                    doc_content = json.loads(doc_response['Body'].read())
                    
                    query_lower = query.lower()
                    title_lower = doc_content.get('title', '').lower()
                    content_lower = doc_content.get('content', '').lower()
                    
                    if any(word in title_lower or word in content_lower for word in query_lower.split()):
                        documents.append(doc_content)
        
        return documents[:5]
        
    except Exception as e:
        st.error(f'S3 ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')
        return []

def generate_bedrock_response(query, documents):
    """ê¸°ì¡´ ë°©ì‹ì˜ Bedrock ì‘ë‹µ ìƒì„±"""
    try:
        context_parts = []
        for doc in documents:
            title = doc.get('title', 'ì œëª© ì—†ìŒ')
            content = doc.get('content', '')[:500]
            context_parts.append(f'ë¬¸ì„œ: {title}\në‚´ìš©: {content}')
        
        context = '\n\n'.join(context_parts)
        
        prompt = f'''ì‚¬ìš©ì ì§ˆë¬¸: {query}

ê´€ë ¨ Notion ë¬¸ì„œë“¤:
{context}

ìœ„ì˜ Notion ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.'''
        
        body = {
            'anthropic_version': 'bedrock-2023-05-31',
            'max_tokens': 2000,
            'temperature': 0.1,
            'messages': [{'role': 'user', 'content': prompt}]
        }
        
        response = bedrock_client.invoke_model(
            modelId='anthropic.claude-3-haiku-20240307-v1:0',
            body=json.dumps(body)
        )
        
        response_body = json.loads(response['body'].read())
        return response_body['content'][0]['text']
        
    except Exception as e:
        return f'ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown('## âš™ï¸ ì„¤ì •')
    
    # ê²€ìƒ‰ ë°©ì‹ ì„ íƒ
    st.markdown('### ğŸ” ê²€ìƒ‰ ë°©ì‹ ì„ íƒ')
    search_method = st.selectbox(
        'ê²€ìƒ‰ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:',
        ['Bedrock KnowledgeBase', 'S3 í‚¤ì›Œë“œ ê²€ìƒ‰'],
        help='KnowledgeBase: Bedrock ê´€ë¦¬í˜• RAG, S3: ì§ì ‘ í‚¤ì›Œë“œ ê²€ìƒ‰'
    )
    
    # ê²€ìƒ‰ ë°©ì‹ë³„ ì„¤ëª…
    if search_method == 'Bedrock KnowledgeBase':
        st.info('ğŸ§  Bedrock KnowledgeBase\n- ê´€ë¦¬í˜• RAG ì„œë¹„ìŠ¤\n- ìë™ ë²¡í„°í™” ë° ì²­í‚¹\n- ìµœì í™”ëœ ê²€ìƒ‰ ì„±ëŠ¥')
    else:
        st.info('ğŸ“ S3 í‚¤ì›Œë“œ ê²€ìƒ‰\n- ì§ì ‘ í‚¤ì›Œë“œ ë§¤ì¹­\n- ë¹ ë¥¸ ì†ë„\n- ë¹„ìš© íš¨ìœ¨ì ')
    
    # ë™ê¸°í™” ìƒíƒœ í™•ì¸ ë²„íŠ¼
    if st.button('ğŸ“Š KnowledgeBase ë™ê¸°í™” ìƒíƒœ í™•ì¸'):
        try:
            with st.spinner('ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì¤‘...'):
                # ìµœê·¼ ingestion job ìƒíƒœ í™•ì¸
                jobs_response = bedrock_agent_client.list_ingestion_jobs(
                    knowledgeBaseId=knowledge_base_id,
                    dataSourceId='X1FS4XS5HU',
                    maxResults=5
                )
                
                if jobs_response.get('ingestionJobSummaries'):
                    latest_job = jobs_response['ingestionJobSummaries'][0]
                    status = latest_job['status']
                    job_id = latest_job['ingestionJobId']
                    updated_at = latest_job['updatedAt']
                    
                    # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    job_detail = bedrock_agent_client.get_ingestion_job(
                        knowledgeBaseId=knowledge_base_id,
                        dataSourceId='X1FS4XS5HU',
                        ingestionJobId=job_id
                    )
                    
                    stats = job_detail['ingestionJob']['statistics']
                    
                    # ìƒíƒœì— ë”°ë¥¸ ì•„ì´ì½˜ê³¼ ìƒ‰ìƒ
                    if status == 'COMPLETE':
                        st.success(f'âœ… **ë™ê¸°í™” ì™„ë£Œ** (Job ID: {job_id})')
                    elif status == 'IN_PROGRESS' or status == 'STARTING':
                        st.info(f'ğŸ”„ **ë™ê¸°í™” ì§„í–‰ ì¤‘** (Job ID: {job_id})')
                    elif status == 'FAILED':
                        st.error(f'âŒ **ë™ê¸°í™” ì‹¤íŒ¨** (Job ID: {job_id})')
                    else:
                        st.warning(f'âš ï¸ **ìƒíƒœ: {status}** (Job ID: {job_id})')
                    
                    # í†µê³„ ì •ë³´ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ìŠ¤ìº”ëœ ë¬¸ì„œ", stats.get('numberOfDocumentsScanned', 0))
                    with col2:
                        st.metric("ì¸ë±ì‹±ëœ ë¬¸ì„œ", stats.get('numberOfNewDocumentsIndexed', 0))
                    with col3:
                        st.metric("ì‹¤íŒ¨í•œ ë¬¸ì„œ", stats.get('numberOfDocumentsFailed', 0))
                    
                    st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {updated_at}")
                    
                    # ì‹¤íŒ¨í•œ ê²½ìš° ì‹¤íŒ¨ ì´ìœ  í‘œì‹œ
                    if status == 'FAILED' and 'failureReasons' in job_detail['ingestionJob']:
                        st.error("ì‹¤íŒ¨ ì´ìœ :")
                        for reason in job_detail['ingestionJob']['failureReasons']:
                            st.code(reason)
                else:
                    st.info('ë™ê¸°í™” ì‘ì—… ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.')
                    
        except Exception as e:
            st.error(f'ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}')
    
    # Knowledge Base ì •ë³´
    st.markdown('### ğŸ§  Knowledge Base')
    st.success(f'Knowledge Base ID: {knowledge_base_id}')
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ í‘œì‹œ
    message_count = len(st.session_state.messages)
    if message_count > 0:
        st.info(f'ğŸ’¬ í˜„ì¬ ëŒ€í™” ê¸°ë¡: {message_count//2}ê°œ ëŒ€í™” (ì´ {message_count}ê°œ ë©”ì‹œì§€)')
        st.caption('ğŸ’¡ ì´ì „ ëŒ€í™” ë‚´ìš©ì´ ìƒˆë¡œìš´ ì§ˆë¬¸ ë‹µë³€ì— í™œìš©ë©ë‹ˆë‹¤.')
    else:
        st.info('ğŸ’¬ ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!')
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button('ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”'):
            st.session_state.messages = []
            st.success('ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!')
            st.rerun()
    
    with col2:
        if st.button('ğŸ”„ ë°ì´í„° ë™ê¸°í™”'):
            try:
                with st.spinner('ë°ì´í„° ë™ê¸°í™” ì¤‘...'):
                    # 1. S3 ë™ê¸°í™” (Notion â†’ S3)
                    response = lambda_client.invoke(
                        FunctionName='NotionChatbotBedrockStack-NotionSyncFunctionFFED61-DntTQBnmfaiG',
                        InvocationType='Event'
                )
                st.success('âœ… S3 ë™ê¸°í™” ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤!')
                
                # 2. KnowledgeBase ë™ê¸°í™” (S3 â†’ KnowledgeBase)
                kb_response = bedrock_agent_client.start_ingestion_job(
                    knowledgeBaseId=knowledge_base_id,
                    dataSourceId='X1FS4XS5HU'  # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë°ì´í„° ì†ŒìŠ¤ ID
                )
                
                ingestion_job_id = kb_response['ingestionJob']['ingestionJobId']
                st.success(f'âœ… KnowledgeBase ë™ê¸°í™” ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤! (Job ID: {ingestion_job_id})')
                st.info('ğŸ’¡ ë™ê¸°í™” ì™„ë£Œê¹Œì§€ 1-2ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
                
            except Exception as e:
                st.error(f'âŒ ë™ê¸°í™” ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}')

# ì´ì „ ë©”ì‹œì§€ë“¤ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.markdown(message['content'])
        if message.get('sources'):
            with st.expander('ğŸ“š ì°¸ê³  ë¬¸ì„œ'):
                bucket_name = 'notion-chatbot-data-965037532757-ap-northeast-2'
                
                for i, source in enumerate(message['sources'], 1):
                    if isinstance(source, dict):
                        # KnowledgeBase citations êµ¬ì¡° ì²˜ë¦¬
                        if 'retrievedReferences' in source:
                            for ref in source['retrievedReferences']:
                                # S3 ìœ„ì¹˜ì—ì„œ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
                                location = ref.get('location', {})
                                title = f"ë¬¸ì„œ {i}"
                                url = ""
                                s3_content = ""
                                
                                if location.get('s3Location'):
                                    s3_loc = location['s3Location']
                                    key = s3_loc.get('objectKey', '')
                                    if key:
                                        try:
                                            title, url, s3_content = get_document_info_from_s3(key, bucket_name)
                                        except Exception as e:
                                            filename = key.split('/')[-1] if '/' in key else key
                                            title = filename.replace('.json', '').replace('_', ' ')
                                
                                # S3 ê²€ìƒ‰ê³¼ ì™„ì „íˆ ë™ì¼í•œ í¬ë§·ìœ¼ë¡œ í‘œì‹œ
                                st.markdown(f'**{i}. {title}**')
                                
                                # S3ì—ì„œ ê°€ì ¸ì˜¨ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ KnowledgeBase ë‚´ìš© ì‚¬ìš©
                                if s3_content:
                                    content_preview = s3_content[:200] + '...' if len(s3_content) > 200 else s3_content
                                else:
                                    # KnowledgeBaseì—ì„œ ê°€ì ¸ì˜¨ ë‚´ìš© ì‚¬ìš©
                                    content = ref.get('content', {})
                                    if isinstance(content, dict):
                                        content_text = content.get('text', '')
                                    else:
                                        content_text = str(content)
                                    content_preview = content_text[:200] + '...' if len(content_text) > 200 else content_text
                                
                                st.markdown(f'ë‚´ìš©: {content_preview}')
                                
                                # URLì´ ìˆìœ¼ë©´ ì›ë³¸ ë³´ê¸° ë§í¬ í‘œì‹œ (S3 ê²€ìƒ‰ê³¼ ë™ì¼)
                                if url:
                                    st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({url})')
                        
                        # S3 ì§ì ‘ ê²€ìƒ‰ ë°©ì‹ (ê¸°ì¡´)
                        elif 'title' in source:
                            st.markdown(f'**{i}. {source.get("title", "ë¬¸ì„œ")}**')
                            content_preview = source.get("content", "ë‚´ìš© ì—†ìŒ")[:200]
                            st.markdown(f'ë‚´ìš©: {content_preview}...')
                            if source.get('url'):
                                st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({source["url"]})')
                        
                        # ê¸°íƒ€ í˜•íƒœ
                        else:
                            st.markdown(f'**{i}. ë¬¸ì„œ {i}**')
                            content_preview = source.get("content", "ë‚´ìš© ì—†ìŒ")[:200]
                            st.markdown(f'ë‚´ìš©: {content_preview}...')
                            if source.get('score'):
                                st.markdown(f'ê´€ë ¨ë„ ì ìˆ˜: {source["score"]:.3f}')
                    st.markdown('---')

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input('ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ì˜ˆ: í”„ë¡œì íŠ¸ ì¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'):
    st.session_state.messages.append({'role': 'user', 'content': prompt})
    
    with st.chat_message('user'):
        st.markdown(prompt)
    
    with st.chat_message('assistant'):
        with st.spinner('ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ¤”'):
            try:
                if search_method == 'Bedrock KnowledgeBase':
                    # KnowledgeBase ì‚¬ìš© (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                    answer, citations = generate_knowledgebase_response_with_context(
                        prompt, 
                        knowledge_base_id, 
                        st.session_state.messages
                    )
                    search_info = 'ğŸ§  Bedrock KnowledgeBase ì‚¬ìš© (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)'
                    
                    st.info(search_info)
                    st.markdown(answer)
                    
                    if citations:
                        with st.expander('ğŸ“š ì°¸ê³  ë¬¸ì„œ', expanded=True):
                            bucket_name = 'notion-chatbot-data-965037532757-ap-northeast-2'
                            
                            for i, citation in enumerate(citations, 1):
                                if 'retrievedReferences' in citation:
                                    for ref in citation['retrievedReferences']:
                                        # S3 ìœ„ì¹˜ì—ì„œ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
                                        location = ref.get('location', {})
                                        title = f"ë¬¸ì„œ {i}"
                                        url = ""
                                        s3_content = ""
                                        
                                        if location.get('s3Location'):
                                            s3_loc = location['s3Location']
                                            key = s3_loc.get('objectKey', '')
                                            if key:
                                                try:
                                                    title, url, s3_content = get_document_info_from_s3(key, bucket_name)
                                                except Exception as e:
                                                    # íŒŒì¼ëª…ì—ì„œ ì œëª© ì¶”ì¶œ
                                                    filename = key.split('/')[-1] if '/' in key else key
                                                    title = filename.replace('.json', '').replace('_', ' ')
                                        
                                        # S3 ê²€ìƒ‰ê³¼ ì™„ì „íˆ ë™ì¼í•œ í¬ë§·ìœ¼ë¡œ í‘œì‹œ
                                        st.markdown(f'**{i}. {title}**')
                                        
                                        # S3ì—ì„œ ê°€ì ¸ì˜¨ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ KnowledgeBase ë‚´ìš© ì‚¬ìš©
                                        if s3_content:
                                            content_preview = s3_content[:200] + '...' if len(s3_content) > 200 else s3_content
                                        else:
                                            # KnowledgeBaseì—ì„œ ê°€ì ¸ì˜¨ ë‚´ìš© ì‚¬ìš©
                                            content = ref.get('content', {})
                                            if isinstance(content, dict):
                                                content_text = content.get('text', '')
                                            else:
                                                content_text = str(content)
                                            content_preview = content_text[:200] + '...' if len(content_text) > 200 else content_text
                                        
                                        st.markdown(f'ë‚´ìš©: {content_preview}')
                                        
                                        # URLì´ ìˆìœ¼ë©´ ì›ë³¸ ë³´ê¸° ë§í¬ í‘œì‹œ (S3 ê²€ìƒ‰ê³¼ ë™ì¼)
                                        if url:
                                            st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({url})')
                                        
                                        st.markdown('---')
                        
                        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                        st.session_state.messages.append({
                            'role': 'assistant', 
                            'content': answer,
                            'sources': citations
                        })
                    else:
                        st.warning('ì°¸ê³  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                        st.session_state.messages.append({
                            'role': 'assistant', 
                            'content': answer
                        })
                
                else:
                    # S3 ì§ì ‘ ê²€ìƒ‰ ì‚¬ìš© (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                    bucket_name = f'notion-chatbot-data-965037532757-ap-northeast-2'
                    answer, documents = generate_s3_response_with_context(
                        prompt, 
                        bucket_name, 
                        st.session_state.messages
                    )
                    search_info = 'ğŸ“ S3 í‚¤ì›Œë“œ ê²€ìƒ‰ ì‚¬ìš© (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í¬í•¨)'
                    
                    st.info(search_info)
                    st.markdown(answer)
                    
                    if documents:
                        # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                        with st.expander('ğŸ“š ì°¸ê³  ë¬¸ì„œ', expanded=True):
                            for i, doc in enumerate(documents[:3], 1):
                                st.markdown(f'**{i}. {doc.get("title", "ë¬¸ì„œ")}**')
                                content_preview = doc.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]
                                st.markdown(f'ë‚´ìš©: {content_preview}...')
                                if doc.get('url'):
                                    st.markdown(f'[ğŸ“„ ì›ë³¸ ë³´ê¸°]({doc["url"]})')
                                st.markdown('---')
                        
                        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                        st.session_state.messages.append({
                            'role': 'assistant', 
                            'content': answer,
                            'sources': documents
                        })
                    else:
                        no_result_msg = 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Notion ë°ì´í„°ê°€ ë™ê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.'
                        st.markdown(no_result_msg)
                        st.session_state.messages.append({'role': 'assistant', 'content': no_result_msg})
                    
            except Exception as e:
                error_msg = f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
                st.error(error_msg)
                st.session_state.messages.append({'role': 'assistant', 'content': error_msg})

st.markdown('---')
st.markdown('<div style="text-align: center; color: #666; padding: 1rem;"><p>ğŸ§  Bedrock KnowledgeBase vs ğŸ“ S3 í‚¤ì›Œë“œ ê²€ìƒ‰ ë¹„êµ ë°ëª¨</p><p>ğŸ”„ ê´€ë¦¬í˜• RAG ì„œë¹„ìŠ¤ì™€ ì§ì ‘ êµ¬í˜„ ë°©ì‹ì˜ ì°¨ì´ë¥¼ ì²´í—˜í•´ë³´ì„¸ìš”</p></div>', unsafe_allow_html=True)
